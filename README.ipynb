{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README - *Finding TikTok Affiliates In Beauty*\n",
    "\n",
    "This notebook walks through the code and scripts used to extract TikTok user's accounts for the purposes of finding affiliates for marketing agencies. The accounts must meet the following criteria:\n",
    "\n",
    "- In the makeup, hair care, and beauty world\n",
    "- Have less than 50K followers\n",
    "- Have an email in their description\n",
    "\n",
    "After scraping accounts and emails that match the above criteria, we leverage the Python SDK for Google's Gemini API to provide a brief summary of the eligible accounts using their TikToks and bio. \n",
    "\n",
    "Individual python scripts were written to be run in the same order as defined by the sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Section 0 -- Data Collection*\n",
    "\n",
    "We start by defining our functions used to scrape the TikTok users by trending videos for specific hashtags. We use the unofficial TikTok API package to collect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TikTokApi import TikTokApi\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "# set env variables\n",
    "OUTPUT_PATH = os.path.join(os.environ['DATAFILES_PATH'], 'TikTok-Users')\n",
    "MS_TOKEN = os.environ['MS_TOKEN'] # make env variable\n",
    "\n",
    "def get_user_url(video):\n",
    "  \n",
    "    # Extract user ID from the video object\n",
    "    user_id = video.as_dict['author']['uniqueId']\n",
    "\n",
    "    # Construct the user URL using the user ID\n",
    "    user_url = f\"https://www.tiktok.com/@{user_id}\"\n",
    "    return user_url\n",
    "\n",
    "def get_video_url(video):\n",
    "\n",
    "    user_id = video.as_dict['author']['uniqueId']\n",
    "    vid_id = video.as_dict['video']['id']\n",
    "\n",
    "    # Construct the user URL using the user ID\n",
    "    vid_url = f\"https://www.tiktok.com/@{user_id}/video/{vid_id}\"\n",
    "    return vid_url\n",
    "\n",
    "def is_over_50k_follers(video):\n",
    "\n",
    "    follower_count = video.as_dict['authorStats']['followerCount']\n",
    "\n",
    "    print(f\"Follower Count: {follower_count}\")\n",
    "\n",
    "    if follower_count > 50000:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# function to fetch follower count of user\n",
    "def get_follow_cnt(video):\n",
    "\n",
    "    return video.as_dict['authorStats']['followerCount']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our hashtags and collect the data for today ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_sample_size = 25\n",
    "iterations = 40\n",
    "hashtags = [\"makeup\", \"beauty\", \"skincare\", \"haircare\", \"skincareroutine\", \"haircareroutine\", \"makeuproutine\"]\n",
    "videos = []\n",
    "\n",
    "async with TikTokApi() as api:\n",
    "    await api.create_sessions(ms_tokens=[MS_TOKEN], num_sessions=1, sleep_after=3, headless=False)\n",
    "\n",
    "    for ihashtag in hashtags:\n",
    "\n",
    "        print(f\"Finding trending videos with #{ihashtag} ...\\n\\n\")\n",
    "\n",
    "        tag = api.hashtag(name=ihashtag) # add other keywords and search criteria\n",
    "\n",
    "        for i in range(iterations):\n",
    "            \n",
    "            print(20*\"-\", f\"SCRAPING SAMPLE #{i+1}\", 20*\"-\")\n",
    "            async for video in tag.videos(count=post_sample_size, cursor=post_sample_size*i):\n",
    "                \n",
    "                # save video\n",
    "                print(f\"Saved {video} ...\")\n",
    "                videos.append(video)\n",
    "\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Section 1 -- Data Filtering & Cleaning*\n",
    "\n",
    "We now filter through the collected users based on follower count and store in local database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_urls = []\n",
    "user_bios = []\n",
    "follower_count = []\n",
    "\n",
    "async with TikTokApi() as api:\n",
    "    await api.create_sessions(ms_tokens=[MS_TOKEN], num_sessions=1, sleep_after=3, headless=False)\n",
    "\n",
    "    for i, video in enumerate(videos):\n",
    "\n",
    "        print(20*\"-\", f\" FILTERING TIKTOK #{i+1} ({100*((i+1)/len(videos)):.2f}%)\", 20*\"-\")\n",
    "\n",
    "        if is_over_50k_follers(video):\n",
    "            print(\"... Skipping\\n\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        user_url = get_user_url(video)\n",
    "        vid_url = get_video_url(video)\n",
    "        num_followers = get_follow_cnt(video)\n",
    "\n",
    "        print(f\"Video URL: {vid_url}\")\n",
    "        print(f\"User URL: {user_url}\\n\")\n",
    "        \n",
    "        user_urls.append(user_url)\n",
    "        follower_count.append(num_followers)\n",
    "\n",
    "        # get user bio\n",
    "        user_data = await api.user(username=video.as_dict['author']['uniqueId']).info()\n",
    "        user_bios.append(user_data['userInfo']['user']['signature'])\n",
    "    \n",
    "\n",
    "user_df = pd.DataFrame({\"User\":user_urls, \"Follower Count\":follower_count, \"Account Bio\":user_bios})\n",
    "user_df = user_df.drop_duplicates()\n",
    "user_df[\"Hashtags Searched\"] = \"/\".join(hashtags)\n",
    "\n",
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y-%m-%d\") \n",
    "user_df.to_excel(os.path.join(OUTPUT_PATH,  f'beauty_usrs_{date_string}.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now filter through the collected users based on follower count and store in local database.\n",
    "\n",
    "Now we scrape the eligible user's bios for emails. Once complete, we attach the emails to their associated rows in our DataFrame and update the final result to our local database ... We start by loading the regular expressions library and defining a function to be applied to each account bio to extract any possible email:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the regular expressions library\n",
    "import re\n",
    "\n",
    "def extract_emails(text):\n",
    "    # Regular expression to find email addresses\n",
    "    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    emails = re.findall(pattern, text)\n",
    "    return emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the function above to extract the associated emails..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to extract emails and create a new column 'Email'\n",
    "user_df['Email'] = user_df['Account Bio'].apply(extract_emails)\n",
    "\n",
    "# convert list of emails to a single string, if any emails are found\n",
    "user_df['Email'] = user_df['Email'].apply(lambda x: ', '.join(x) if x else '')\n",
    "\n",
    "# remove users without email in bio \n",
    "user_df = user_df[user_df['Email']!=\"\"]\n",
    "\n",
    "now = datetime.now()\n",
    "date_string = now.strftime(\"%Y-%m-%d\") \n",
    "user_df.to_excel(os.path.join(OUTPUT_PATH,  f'beauty_usrs_{date_string}.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Section 2 -- Account Summary Generations*\n",
    "\n",
    "We now use the [Python SDK for Gemini API](https://ai.google.dev/tutorials/python_quickstart) to write a brief summary of the user's content based on both the user's bio and videos. \n",
    "\n",
    "As an example, we can either grab a previously filtered dataset or use something recently collected and filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_previous_collection = True\n",
    "coll_date = '2024-04-07'\n",
    "\n",
    "if use_previous_collection:\n",
    "    user_df = pd.read_excel(os.path.join(OUTPUT_PATH,  f'beauty_usrs_{coll_date}.xlsx'))\n",
    "    user_df.loc[user_df['Email'].isna(), 'Email'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Section 3 -- Automate Process*\n",
    "\n",
    "In this section, we begin with a brief discussion about the following processes:\n",
    "\n",
    "- Automating data collection on a daily basis using AWS.\n",
    "- Storing results on a cloud database.\n",
    "- Providing a U.I. for employee's to easily navigate and use in order to contact potential affiliates via email."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiktok-scrape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
